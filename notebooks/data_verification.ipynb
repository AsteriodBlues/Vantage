{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Verification and Quality Assessment\n",
    "\n",
    "Comprehensive verification of the collected 2018-2024 F1 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data/raw/race_data.csv')\n",
    "\n",
    "if not data_path.exists():\n",
    "    print(f\"ERROR: Data file not found at {data_path}\")\n",
    "    print(\"Please run the data collection notebook first.\")\n",
    "else:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\" Loaded: {data_path}\")\n",
    "    print(f\"File size: {data_path.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Shape:\")\n",
    "print(f\"Rows: {df.shape[0]:,}\")\n",
    "print(f\"Columns: {df.shape[1]}\")\n",
    "print(f\"\\nMemory Usage: {df.memory_usage(deep=True).sum() / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFirst few rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique Value Counts:\")\n",
    "print(f\"\\nYears: {df['year'].nunique()}\")\n",
    "print(f\"Unique years: {sorted(df['year'].unique())}\")\n",
    "\n",
    "print(f\"\\nRaces: {df['race_name'].nunique()}\")\n",
    "print(f\"Circuits: {df['circuit'].nunique()}\")\n",
    "print(f\"Drivers: {df['DriverNumber'].nunique()}\")\n",
    "print(f\"Teams: {df['TeamName'].nunique() if 'TeamName' in df.columns else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Races per year\n",
    "races_by_year = df.groupby('year')['race_name'].nunique().sort_index()\n",
    "print(\"\\nRaces per year:\")\n",
    "for year, count in races_by_year.items():\n",
    "    print(f\"  {year}: {count} races\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Records per year\n",
    "records_by_year = df.groupby('year').size().sort_index()\n",
    "print(\"\\nRecords per year:\")\n",
    "for year, count in records_by_year.items():\n",
    "    avg_per_race = count / races_by_year[year]\n",
    "    print(f\"  {year}: {count} records ({avg_per_race:.1f} avg per race)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing': missing,\n",
    "    'Percentage': missing_pct\n",
    "}).sort_values('Missing', ascending=False)\n",
    "\n",
    "print(missing_df[missing_df['Missing'] > 0])\n",
    "\n",
    "if missing_df['Missing'].sum() == 0:\n",
    "    print(\"\\n No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check critical columns\n",
    "critical_cols = ['Position', 'GridPosition', 'DriverNumber', 'year', 'round']\n",
    "print(\"\\nMissing values in critical columns:\")\n",
    "for col in critical_cols:\n",
    "    if col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        print(f\"  {col}: {missing_count}\")\n",
    "        if missing_count > 0:\n",
    "            print(f\"    WARNING: Critical column has missing data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Position values\n",
    "print(\"Position Analysis:\")\n",
    "print(f\"\\nUnique Position values: {df['Position'].nunique()}\")\n",
    "print(f\"Position range: {df['Position'].min()} to {df['Position'].max()}\")\n",
    "print(f\"Data type: {df['Position'].dtype}\")\n",
    "\n",
    "# Convert to numeric for analysis\n",
    "df['Position_num'] = pd.to_numeric(df['Position'], errors='coerce')\n",
    "print(f\"\\nNumeric conversion successful\")\n",
    "print(f\"Min position: {df['Position_num'].min()}\")\n",
    "print(f\"Max position: {df['Position_num'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GridPosition values\n",
    "print(\"GridPosition Analysis:\")\n",
    "print(f\"\\nUnique GridPosition values: {df['GridPosition'].nunique()}\")\n",
    "print(f\"Data type: {df['GridPosition'].dtype}\")\n",
    "\n",
    "df['GridPosition_num'] = pd.to_numeric(df['GridPosition'], errors='coerce')\n",
    "print(f\"\\nMin grid: {df['GridPosition_num'].min()}\")\n",
    "print(f\"Max grid: {df['GridPosition_num'].max()}\")\n",
    "\n",
    "# Check for pit lane starts (grid position 0)\n",
    "pit_starts = (df['GridPosition_num'] == 0).sum()\n",
    "print(f\"\\nPit lane starts: {pit_starts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNF Analysis\n",
    "print(\"DNF Analysis:\")\n",
    "\n",
    "total_entries = len(df)\n",
    "finished = (df['Status'] == 'Finished').sum()\n",
    "dnf = total_entries - finished\n",
    "dnf_rate = (dnf / total_entries) * 100\n",
    "\n",
    "print(f\"\\nTotal entries: {total_entries:,}\")\n",
    "print(f\"Finished: {finished:,} ({100-dnf_rate:.1f}%)\")\n",
    "print(f\"DNFs: {dnf:,} ({dnf_rate:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top DNF reasons\n",
    "dnf_data = df[df['Status'] != 'Finished']\n",
    "if len(dnf_data) > 0:\n",
    "    print(\"\\nTop 10 DNF reasons:\")\n",
    "    print(dnf_data['Status'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for races with unusual driver counts\n",
    "drivers_per_race = df.groupby(['year', 'round', 'race_name']).size()\n",
    "\n",
    "print(\"Races with unusual driver counts:\")\n",
    "unusual = drivers_per_race[(drivers_per_race < 19) | (drivers_per_race > 22)]\n",
    "if len(unusual) > 0:\n",
    "    print(unusual)\n",
    "else:\n",
    "    print(\"None found - all races have 19-22 drivers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate entries\n",
    "duplicates = df.duplicated(subset=['year', 'round', 'DriverNumber']).sum()\n",
    "print(f\"\\nDuplicate entries: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"\\nWARNING: Found duplicate entries!\")\n",
    "    dup_rows = df[df.duplicated(subset=['year', 'round', 'DriverNumber'], keep=False)]\n",
    "    print(dup_rows[['year', 'round', 'race_name', 'DriverNumber', 'FullName']].sort_values(['year', 'round']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Grid position distribution\n",
    "axes[0, 0].hist(df['GridPosition_num'].dropna(), bins=20, edgecolor='black')\n",
    "axes[0, 0].set_title('Grid Position Distribution', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Grid Position')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Finish position distribution\n",
    "axes[0, 1].hist(df['Position_num'].dropna(), bins=20, edgecolor='black', color='orange')\n",
    "axes[0, 1].set_title('Finish Position Distribution', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Finish Position')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Races per year\n",
    "races_by_year.plot(kind='bar', ax=axes[1, 0], color='green', edgecolor='black')\n",
    "axes[1, 0].set_title('Races per Year', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Year')\n",
    "axes[1, 0].set_ylabel('Number of Races')\n",
    "axes[1, 0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Records per circuit\n",
    "circuit_counts = df['circuit'].value_counts().head(15)\n",
    "circuit_counts.plot(kind='barh', ax=axes[1, 1], color='purple', edgecolor='black')\n",
    "axes[1, 1].set_title('Top 15 Circuits by Records', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Number of Records')\n",
    "axes[1, 1].set_ylabel('Circuit')\n",
    "axes[1, 1].grid(alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numeric Columns Summary:\")\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notable Issues and Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = []\n",
    "\n",
    "# Check 2020 for fewer races (COVID)\n",
    "races_2020 = df[df['year'] == 2020]['race_name'].nunique()\n",
    "if races_2020 < 17:\n",
    "    issues.append(f\"2020 has only {races_2020} races (COVID impact)\")\n",
    "\n",
    "# Check for missing critical data\n",
    "if df['Position'].isnull().sum() > 0:\n",
    "    issues.append(f\"{df['Position'].isnull().sum()} missing Position values\")\n",
    "\n",
    "if df['GridPosition'].isnull().sum() > 0:\n",
    "    issues.append(f\"{df['GridPosition'].isnull().sum()} missing GridPosition values\")\n",
    "\n",
    "# Check DNF rate\n",
    "if dnf_rate > 25:\n",
    "    issues.append(f\"High DNF rate: {dnf_rate:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if issues:\n",
    "    print(\"\\nIssues found:\")\n",
    "    for i, issue in enumerate(issues, 1):\n",
    "        print(f\"  {i}. {issue}\")\n",
    "else:\n",
    "    print(\"\\n No major issues found!\")\n",
    "\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(f\"  Years: {df['year'].min()} - {df['year'].max()}\")\n",
    "print(f\"  Total records: {len(df):,}\")\n",
    "print(f\"  Total races: {df['race_name'].nunique()}\")\n",
    "print(f\"  DNF rate: {dnf_rate:.1f}%\")\n",
    "print(f\"  Duplicates: {duplicates}\")\n",
    "print(\"\\nReady for data cleaning and analysis!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
