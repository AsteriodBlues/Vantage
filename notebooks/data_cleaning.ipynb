{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Processing\n",
    "\n",
    "Clean and standardize the collected F1 race data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_processing import DataProcessor\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw race data\n",
    "raw_data_path = Path('../data/raw/race_data.csv')\n",
    "\n",
    "if not raw_data_path.exists():\n",
    "    print(f\"ERROR: {raw_data_path} not found\")\n",
    "    print(\"Run the data collection notebook first.\")\n",
    "else:\n",
    "    df_raw = pd.read_csv(raw_data_path)\n",
    "    print(f\"Loaded: {raw_data_path}\")\n",
    "    print(f\"Shape: {df_raw.shape}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    display(df_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Cleaning - Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BEFORE CLEANING:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Records: {len(df_raw):,}\")\n",
    "print(f\"Columns: {df_raw.shape[1]}\")\n",
    "print(f\"\\nUnique circuits: {df_raw['circuit'].nunique()}\")\n",
    "print(f\"Unique teams: {df_raw['TeamName'].nunique() if 'TeamName' in df_raw.columns else 'N/A'}\")\n",
    "print(f\"\\nSample circuit names:\")\n",
    "print(df_raw['circuit'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processor with settings\n",
    "processor = DataProcessor(\n",
    "    remove_dnfs=False,         # Keep DNFs but flag them\n",
    "    standardize_names=True     # Standardize circuit and team names\n",
    ")\n",
    "\n",
    "print(\"DataProcessor initialized\")\n",
    "print(\"Settings:\")\n",
    "print(f\"  remove_dnfs: {processor.remove_dnfs}\")\n",
    "print(f\"  standardize_names: {processor.standardize_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "print(\"Starting data cleaning...\\n\")\n",
    "df_clean = processor.clean_data(df_raw)\n",
    "print(\"\\nCleaning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle DNFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add DNF flags\n",
    "print(\"Processing DNF data...\\n\")\n",
    "df_processed = processor.handle_dnfs(df_clean)\n",
    "print(\"\\nDNF processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Cleaning - Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nBefore -> After:\")\n",
    "print(f\"  Records: {len(df_raw):,} -> {len(df_processed):,}\")\n",
    "print(f\"  Circuits: {df_raw['circuit'].nunique()} -> {df_processed['circuit'].nunique()}\")\n",
    "\n",
    "if 'TeamName' in df_raw.columns:\n",
    "    print(f\"  Teams: {df_raw['TeamName'].nunique()} -> {df_processed['TeamName'].nunique()}\")\n",
    "\n",
    "# Get detailed stats\n",
    "stats = processor.get_cleaning_summary()\n",
    "print(\"\\nDetailed Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show new columns added\n",
    "new_cols = set(df_processed.columns) - set(df_raw.columns)\n",
    "if new_cols:\n",
    "    print(f\"\\nNew columns added: {list(new_cols)}\")\n",
    "    print(\"\\nSample of new data:\")\n",
    "    display(df_processed[['year', 'round', 'FullName', 'Position', 'is_dnf', \n",
    "                          'completed_race', 'position_change']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Cleaning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check specific races to verify cleaning worked\n",
    "print(\"Verification - Sample race (2024 Round 1):\")\n",
    "sample_race = df_processed[(df_processed['year'] == 2024) & (df_processed['round'] == 1)]\n",
    "print(f\"\\nDrivers in race: {len(sample_race)}\")\n",
    "print(\"\\nSample results:\")\n",
    "display(sample_race[['FullName', 'TeamName', 'GridPosition', 'Position', \n",
    "                     'position_change', 'is_dnf', 'Status']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"\\nData types after cleaning:\")\n",
    "print(df_processed[['Position', 'GridPosition', 'Points', 'is_dnf']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no critical data lost\n",
    "print(\"\\nData integrity check:\")\n",
    "print(f\"Original unique races: {df_raw.groupby(['year', 'round']).ngroups}\")\n",
    "print(f\"Cleaned unique races: {df_processed.groupby(['year', 'round']).ngroups}\")\n",
    "\n",
    "if df_raw.groupby(['year', 'round']).ngroups == df_processed.groupby(['year', 'round']).ngroups:\n",
    "    print(\" ✓ All races retained\")\n",
    "else:\n",
    "    print(\" ⚠ Some races removed - check cleaning logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "from config import PROCESSED_DATA_DIR\n",
    "\n",
    "# CSV format\n",
    "csv_path = PROCESSED_DATA_DIR / 'processed_race_data.csv'\n",
    "df_processed.to_csv(csv_path, index=False)\n",
    "csv_size = csv_path.stat().st_size / 1024\n",
    "\n",
    "# Pickle format for faster loading\n",
    "pkl_path = PROCESSED_DATA_DIR / 'processed_race_data.pkl'\n",
    "df_processed.to_pickle(pkl_path)\n",
    "pkl_size = pkl_path.stat().st_size / 1024\n",
    "\n",
    "print(\"\\nSaved cleaned data:\")\n",
    "print(f\"  CSV: {csv_path} ({csv_size:.2f} KB)\")\n",
    "print(f\"  Pickle: {pkl_path} ({pkl_size:.2f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATA CLEANING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nBefore -> After:\")\n",
    "print(f\"  Total records: {len(df_raw):,} -> {len(df_processed):,}\")\n",
    "print(f\"  Records removed: {len(df_raw) - len(df_processed)}\")\n",
    "\n",
    "print(\"\\nData quality improvements:\")\n",
    "print(f\"  ✓ Position/GridPosition converted to numeric\")\n",
    "print(f\"  ✓ Circuit names standardized ({stats.get('circuits_before', 0)} -> {stats.get('circuits_after', 0)})\")\n",
    "print(f\"  ✓ Team names standardized ({stats.get('teams_before', 0)} -> {stats.get('teams_after', 0)})\")\n",
    "print(f\"  ✓ DNF flags added ({stats.get('dnf_count', 0)} DNFs flagged)\")\n",
    "print(f\"  ✓ Derived columns added (position_change, is_dnf, etc.)\")\n",
    "print(f\"  ✓ {stats.get('errors_removed', 0)} erroneous records removed\")\n",
    "\n",
    "print(\"\\nFiles saved:\")\n",
    "print(f\"  - {csv_path}\")\n",
    "print(f\"  - {pkl_path}\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Begin exploratory data analysis\")\n",
    "print(\"  2. Create visualizations\")\n",
    "print(\"  3. Start feature engineering\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
